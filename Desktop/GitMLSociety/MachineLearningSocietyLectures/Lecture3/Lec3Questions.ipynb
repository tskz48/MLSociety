{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.000e+01 6.500e+01 8.450e+03 ... 0.000e+00 2.000e+00 2.008e+03]\n",
      " [2.000e+01 8.000e+01 9.600e+03 ... 0.000e+00 5.000e+00 2.007e+03]\n",
      " [6.000e+01 6.800e+01 1.125e+04 ... 0.000e+00 9.000e+00 2.008e+03]\n",
      " ...\n",
      " [7.000e+01 6.600e+01 9.042e+03 ... 2.500e+03 5.000e+00 2.010e+03]\n",
      " [2.000e+01 6.800e+01 9.717e+03 ... 0.000e+00 4.000e+00 2.010e+03]\n",
      " [2.000e+01 7.500e+01 9.937e+03 ... 0.000e+00 6.000e+00 2.008e+03]]\n",
      "[208500 181500 223500 ... 266500 142125 147500]\n",
      "[5.61462979e+01 7.06654773e+01 1.01229563e+04 6.21231044e+00\n",
      " 5.56110616e+00 1.97226494e+03 1.98568332e+03 1.08487957e+02\n",
      " 4.38399643e+02 4.45896521e+01 5.94125781e+02 1.07711508e+03\n",
      " 1.17358430e+03 3.53258698e+02 4.56824264e+00 1.53141124e+03\n",
      " 4.13916146e-01 5.53077609e-02 1.58073149e+00 3.81801963e-01\n",
      " 2.86440678e+00 1.04281891e+00 6.57627119e+00 6.03925067e-01\n",
      " 1.97839964e+03 1.87867975e+00 5.02955397e+02 9.26101695e+01\n",
      " 4.61302409e+01 2.18447814e+01 3.34879572e+00 1.61008029e+01\n",
      " 2.93487957e+00 2.34290812e+01 6.33987511e+00 2.00779572e+03]\n",
      "[4.17540482e+01 2.42559860e+01 8.12567592e+03 1.38020610e+00\n",
      " 1.06775972e+00 3.09539140e+01 2.10165938e+01 1.89416424e+02\n",
      " 4.68176077e+02 1.57758313e+02 4.50058782e+02 4.45457680e+02\n",
      " 3.86001969e+02 4.38366133e+02 4.15769123e+01 5.23490250e+02\n",
      " 5.12069238e-01 2.32449852e-01 5.49871285e-01 4.98515871e-01\n",
      " 7.71590703e-01 2.06808060e-01 1.59048487e+00 6.32274070e-01\n",
      " 2.58113129e+01 6.54021012e-01 1.91157724e+02 1.21814254e+02\n",
      " 6.43613030e+01 6.12547436e+01 2.97592574e+01 5.77760419e+01\n",
      " 4.02041428e+01 1.65685866e+02 2.68665509e+00 1.33444702e+00]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "df_num = df.select_dtypes(include = ['float64', 'int64'])\n",
    "df_num = df_num.dropna()\n",
    "x_train = df_num.iloc[:,1:-1]\n",
    "y_train = df_num['SalePrice']\n",
    "X_features = x_train.columns\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "def zscore_normalize_features(X):\n",
    "    mu = np.mean(X, axis=0)                \n",
    "    sigma = np.std(X, axis=0)                  \n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    "\n",
    "X_norm_train, X_mu, X_sigma = zscore_normalize_features(x_train)\n",
    "\n",
    "print(X_mu)\n",
    "print(X_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0000e+01 8.0000e+01 1.1622e+04 ... 0.0000e+00 6.0000e+00 2.0100e+03]\n",
      " [2.0000e+01 8.1000e+01 1.4267e+04 ... 1.2500e+04 6.0000e+00 2.0100e+03]\n",
      " [6.0000e+01 7.4000e+01 1.3830e+04 ... 0.0000e+00 3.0000e+00 2.0100e+03]\n",
      " ...\n",
      " [1.6000e+02 2.1000e+01 1.8940e+03 ... 0.0000e+00 4.0000e+00 2.0060e+03]\n",
      " [2.0000e+01 1.6000e+02 2.0000e+04 ... 0.0000e+00 9.0000e+00 2.0060e+03]\n",
      " [6.0000e+01 7.4000e+01 9.6270e+03 ... 0.0000e+00 1.1000e+01 2.0060e+03]]\n",
      "259679.63656322556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Question 1\n",
    "\n",
    "\n",
    "\n",
    "df=pd.read_csv('./test.csv')\n",
    "\n",
    "df_num = df.select_dtypes(include = ['float64', 'int64']) #selecting numeric columns, (data type float or integer)\n",
    "df_num = df_num.dropna() #removing missing values\n",
    "\n",
    "\n",
    "x_test = df_num.iloc[:,1:] #selects all rows, but excludes the first column (at index 0). This is because the first column does not provide useful information for our regression analysis, as it is only an identifier column.\n",
    "x_test = np.array(x_test) #converts dataframe into a numpy array\n",
    "print(x_test)\n",
    "def zscore_normalize_features(X): #performs z-score normalisation, so our features will be transformed to have a mean of 0 and standard deviation 1. This normalisation is particularly useful if different features have different units. If one features tends to have values of much larger magnitude, it will dominate the training process, so z-score normalisation helps prevent that.\n",
    "                     \n",
    "    X_norm = (X - X_mu) / X_sigma      \n",
    "\n",
    "    return (X_norm, X_mu, X_sigma)\n",
    "\n",
    "\n",
    "X_norm_test, X_mu, X_sigma = zscore_normalize_features(x_test)\n",
    "\n",
    "\n",
    "w_final=np.array([-8011.41949503, -2554.88144257,  4371.01684486, 25300.23441283,\n",
    "  4971.24485624,  7414.6478549,   3530.17191891,  6203.30658114,\n",
    "  4930.42056713,   138.71580287, -1017.24755316,  4203.24404008,\n",
    "  7060.34994443,  8485.56937076,   249.84729751, 12331.62047256,\n",
    "  4557.03199214,   566.25084138,  4001.4751966,    264.02161654,\n",
    " -7473.23854297, -4736.50310288,  8860.92989084,  3198.91077193,\n",
    "  -412.32382937,  9937.32513012,  2198.63407278,  2656.09106672,\n",
    "  -277.77367228,   265.29134584,  1002.93366631,  3310.6169966,\n",
    " -2516.37594624,  -682.08787893,  -527.42969216,  -384.33861248])  #weight matrix\n",
    "\n",
    "\n",
    "b_final=185497.75 #final bias\n",
    "\n",
    "\n",
    "m,_ = X_norm_test.shape\n",
    "for i in range (m):\n",
    "  predictions=np.dot(X_norm_test[i],w_final) +b_final   #predicted values from applying our model to our normalised testing set.\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.09229529 -0.23357027 ... -0.14140664 -1.61534509\n",
      "   0.15308355]\n",
      " [ 1.         -0.86569565  0.38483378 ... -0.14140664 -0.49871497\n",
      "  -0.59629052]\n",
      " [ 1.          0.09229529 -0.10988946 ... -0.14140664  0.99012519\n",
      "   0.15308355]\n",
      " ...\n",
      " [ 1.          0.33179303 -0.19234334 ... 14.94738799 -0.49871497\n",
      "   1.65183171]\n",
      " [ 1.         -0.86569565 -0.10988946 ... -0.14140664 -0.87092501\n",
      "   1.65183171]\n",
      " [ 1.         -0.86569565  0.17869909 ... -0.14140664 -0.12650493\n",
      "   0.15308355]]\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.810\n",
      "Model:                            OLS   Adj. R-squared:                  0.804\n",
      "Method:                 Least Squares   F-statistic:                     135.7\n",
      "Date:                Wed, 05 Feb 2025   Prob (F-statistic):               0.00\n",
      "Time:                        16:56:43   Log-Likelihood:                -13358.\n",
      "No. Observations:                1121   AIC:                         2.679e+04\n",
      "Df Residuals:                    1086   BIC:                         2.696e+04\n",
      "Df Model:                          34                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1.855e+05   1098.728    168.837      0.000    1.83e+05    1.88e+05\n",
      "x1         -8371.2259   1439.925     -5.814      0.000   -1.12e+04   -5545.875\n",
      "x2         -2816.6838   1485.463     -1.896      0.058   -5731.387      98.019\n",
      "x3          4431.3620   1278.342      3.466      0.001    1923.061    6939.662\n",
      "x4          2.581e+04   2040.519     12.646      0.000    2.18e+04    2.98e+04\n",
      "x5          5581.4009   1459.717      3.824      0.000    2717.215    8445.587\n",
      "x6          9811.4121   2712.253      3.617      0.000    4489.563    1.51e+04\n",
      "x7          2534.0583   1820.299      1.392      0.164   -1037.643    6105.760\n",
      "x8          5986.4851   1327.051      4.511      0.000    3382.611    8590.359\n",
      "x9          4487.9466   1263.789      3.551      0.000    2008.203    6967.691\n",
      "x10           88.0956   1127.034      0.078      0.938   -2123.316    2299.507\n",
      "x11        -1259.0543   1087.140     -1.158      0.247   -3392.186     874.078\n",
      "x12         3475.9725   1605.879      2.165      0.031     324.995    6626.950\n",
      "x13         7792.5261   1883.714      4.137      0.000    4096.396    1.15e+04\n",
      "x14         9186.2858   1583.964      5.800      0.000    6078.309    1.23e+04\n",
      "x15          350.4821   1153.351      0.304      0.761   -1912.567    2613.531\n",
      "x16         1.347e+04   1679.035      8.020      0.000    1.02e+04    1.68e+04\n",
      "x17         4598.3777   1635.499      2.812      0.005    1389.283    7807.473\n",
      "x18          578.8279   1178.743      0.491      0.623   -1734.044    2891.700\n",
      "x19         2963.6068   1940.233      1.527      0.127    -843.423    6770.636\n",
      "x20         -557.6016   1655.008     -0.337      0.736   -3804.977    2689.774\n",
      "x21        -7895.3024   1662.038     -4.750      0.000   -1.12e+04   -4634.133\n",
      "x22        -4535.5652   1386.524     -3.271      0.001   -7256.135   -1814.995\n",
      "x23         8651.8888   2363.104      3.661      0.000    4015.122    1.33e+04\n",
      "x24         2766.0819   1383.325      2.000      0.046      51.789    5480.374\n",
      "x25        -1268.4492   2347.108     -0.540      0.589   -5873.829    3336.931\n",
      "x26         1.098e+04   2280.364      4.815      0.000    6505.549    1.55e+04\n",
      "x27         1240.2782   2315.640      0.536      0.592   -3303.358    5783.914\n",
      "x28         2624.5761   1220.285      2.151      0.032     230.192    5018.960\n",
      "x29         -149.0140   1253.640     -0.119      0.905   -2608.845    2310.816\n",
      "x30          443.0659   1262.664      0.351      0.726   -2034.472    2920.604\n",
      "x31         1029.0431   1115.772      0.922      0.357   -1160.270    3218.356\n",
      "x32         3349.0539   1178.549      2.842      0.005    1036.562    5661.545\n",
      "x33        -2462.9762   1199.780     -2.053      0.040   -4817.125    -108.828\n",
      "x34         -637.9108   1152.336     -0.554      0.580   -2898.968    1623.147\n",
      "x35         -601.8668   1135.576     -0.530      0.596   -2830.039    1626.305\n",
      "x36         -338.4670   1128.133     -0.300      0.764   -2552.035    1875.101\n",
      "==============================================================================\n",
      "Omnibus:                      436.238   Durbin-Watson:                   1.941\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            65229.851\n",
      "Skew:                          -0.681   Prob(JB):                         0.00\n",
      "Kurtosis:                      40.345   Cond. No.                     8.96e+15\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.04e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "#Add a constant to X_train for the intercept\n",
    "\n",
    "\n",
    "\n",
    "X_b_train = sm.add_constant(X_norm_train) #adds a column of 1s, representing the intercept in the regression model. This is because OLS (Ordinary Least Squares) requires an intercept term to estimate the relationship between variables. We can account for bias by including this intercept term.\n",
    "\n",
    "# Fit the OLS model\n",
    "ols_model = sm.OLS(y_train, X_b_train).fit() #Fits an OLS model with X_b_train as input features and y_train as target values.\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(ols_model.summary()) #prints regression statistics such as R Squared (gives us an idea of how well the features explain variability in the target, for example R^2 = 0.85 means that 85% of the variance in y can be explained by our inputs). p-values, Coefficients, Standard Errors, F-Statistic.\n",
    "\n",
    "X_b_test = sm.add_constant(X_norm_test) #we need to add a column of ones to the testing set aswell, otherwise we will get less accurate predictions. In fact, the constant added will be the same as that of the training set.\n",
    "predictions_test = ols_model.predict(X_b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
